import streamlit as st
import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
from datetime import datetime, timedelta
import urllib3

# ç¦ç”¨ SSL å®‰å…¨è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

st.set_page_config(page_title="è‚¡ç¥¨ RS ç¯©é¸å™¨", page_icon="ğŸ“ˆ", layout="wide")

# --- é€šç”¨å·¥å…·ï¼šæ™‚å€è™•ç† ---
def get_tw_time():
    return datetime.utcnow() + timedelta(hours=8)

# --- 1. è‚¡ç¥¨åœ°åœ– (å°è‚¡å°ˆç”¨) ---
@st.cache_data(ttl=604800)
def get_stock_mapping():
    urls = {
        "TWSE": "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2",
        "TPEX": "https://isin.twse.com.tw/isin/C_public.jsp?strMode=4"
    }
    mapping = {}
    headers = {'User-Agent': 'Mozilla/5.0'}
    for market, url in urls.items():
        try:
            resp = requests.get(url, headers=headers, timeout=10, verify=False)
            resp.encoding = 'ms950'
            soup = BeautifulSoup(resp.text, 'html.parser')
            rows = soup.find_all('tr')
            prefix = "TWSE" if market == "TWSE" else "TPEX"
            for row in rows:
                cols = row.find_all('td')
                if not cols: continue
                text = cols[0].get_text(strip=True).replace('\u3000', ' ')
                parts = text.split(' ')
                if len(parts) >= 2 and parts[0].isdigit():
                    mapping[str(parts[0])] = {"name": parts[1], "prefix": prefix}
        except:
            continue
    return mapping

# --- 2. MoneyDJ æŠ“å– (å°è‚¡å°ˆç”¨) ---
def fetch_moneydj_rs(weeks, min_rank):
    url = f"https://moneydj.emega.com.tw/z/zk/zkf/zkResult.asp?D=1&A=x@250,a@{weeks},b@{min_rank}&site="
    try:
        resp = requests.get(url, timeout=15, verify=False)
        resp.encoding = 'big5'
        match = re.search(r"parent\.sStklistAll\s*=\s*'([^']+)'", resp.text)
        if match:
            raw_codes = match.group(1).encode('utf-8').decode('unicode-escape')
            return [c.strip() for c in raw_codes.split(',') if c.strip().isdigit()]
    except:
        pass
    return []

# --- 3. Google Sheet æŠ“å– (ç¾è‚¡å°ˆç”¨) ---
@st.cache_data(ttl=3600)  # æ¯å°æ™‚æ›´æ–°ä¸€æ¬¡
def fetch_us_rs_from_gsheet(sheet_url):
    try:
        # å°‡ç·¨è¼¯é€£çµè½‰æ›ç‚º CSV å°å‡ºé€£çµ
        csv_url = sheet_url.replace('/edit?usp=sharing', '/export?format=csv')
        df = pd.read_csv(csv_url)
        # å‡è¨­ Google Sheet æ¬„ä½åŒ…å« 'Symbol', 'Name', 'RS Rating', 'Exchange'
        # æ‚¨éœ€è¦æ ¹æ“šè©² Sheet çš„å¯¦éš›æ¨™é¡Œä¿®æ”¹ä¸‹åˆ—æ¬„ä½åç¨±
        return df
    except Exception as e:
        st.error(f"è®€å– Google Sheet å¤±æ•—: {e}")
        return None

# --- 4. ä»‹é¢ä½ˆå±€ ---
st.sidebar.title("ğŸ› ï¸ å¸‚å ´åˆ‡æ›")
market_choice = st.sidebar.radio("é¸æ“‡å¸‚å ´", ["å°è‚¡ (MoneyDJ)", "ç¾è‚¡ (Google Sheet)"])

if market_choice == "å°è‚¡ (MoneyDJ)":
    st.title("ğŸ‡¹ğŸ‡¼ å°è‚¡ RS Rank ç¯©é¸å™¨")
    
    weeks = st.slider("é¸æ“‡é€±æ•¸", 1, 52, 1)
    min_rank = st.number_input("RS Rank å¤§æ–¼ç­‰æ–¼", 1, 99, 80)
    max_count = st.number_input("è‡³å¤šé¡¯ç¤ºå¹¾ç­†", 1, 500, 200)

    mdj_url = f"https://moneydj.emega.com.tw/z/zk/zkf/zkResult.asp?D=1&A=x@250,a@{weeks},b@{min_rank}&site="
    st.markdown(f"ğŸ” [ğŸ”— é–‹å•Ÿ MoneyDJ åŸå§‹ç¶²é ç¢ºèª]({mdj_url})")

    if st.button("ğŸš€ åŸ·è¡Œå°è‚¡ç¯©é¸", type="primary", use_container_width=True):
        with st.spinner('æ­£åœ¨åŒæ­¥æ•¸æ“š...'):
            mapping = get_stock_mapping()
            codes = fetch_moneydj_rs(weeks, min_rank)
            if codes:
                final_codes = codes[:max_count]
                tv_list = [f"{mapping.get(c, {'prefix':'TWSE'})['prefix']}:{c}" for c in final_codes]
                display_data = [{"ä»£è™Ÿ": c, "åç¨±": mapping.get(c, {'name':'åç¨±å¾…æŸ¥'})['name'], "å¸‚å ´": mapping.get(c, {'prefix':'TWSE'})['prefix']} for c in final_codes]
                
                # ä¸‹è¼‰èˆ‡é¡¯ç¤ºé‚è¼¯ (ç¶­æŒåŸæ¨£)
                csv_string = ",".join(tv_list)
                st.code(csv_string)
                st.download_button("ğŸ“¥ ä¸‹è¼‰å°è‚¡æ¸…å–®", csv_string, f"TW_{get_tw_time().strftime('%Y_%m_%d')}.txt")
                st.dataframe(display_data, use_container_width=True)
            else:
                st.warning("æŸ¥ç„¡ç¬¦åˆæ¢ä»¶ä¹‹è‚¡ç¥¨ã€‚")

else:
    st.title("ğŸ‡ºğŸ‡¸ ç¾è‚¡ RS Rank ç¯©é¸å™¨")
    st.info("æ•¸æ“šä¾†æºï¼šæŒ‡å®šçš„ Google Sheet å…¬é–‹æ¸…å–®")

    min_rs = st.number_input("RS Rank æœ€ä½åˆ†æ•¸", 1, 99, 90)
    
    gsheet_url = "https://docs.google.com/spreadsheets/d/18EWLoHkh2aiJIKQsJnjOjPo63QFxkUE2U_K8ffHCn1E/edit?usp=sharing"
    
    if st.button("ğŸš€ åŸ·è¡Œç¾è‚¡ç¯©é¸", type="primary", use_container_width=True):
        with st.spinner('è®€å– Google Sheet ä¸­...'):
            df = fetch_us_rs_from_gsheet(gsheet_url)
            if df is not None:
                # è‡ªå‹•åµæ¸¬å¯èƒ½çš„ RS æ¬„ä½åç¨± (ä¾‹å¦‚ 'RS Rating', 'RS', 'RS Rank')
                rs_col = next((c for c in df.columns if 'RS' in c.upper()), None)
                symbol_col = next((c for c in df.columns if 'SYMBOL' in c.upper() or 'TICKER' in c.upper()), None)
                
                if rs_col and symbol_col:
                    # ç¯©é¸æ¢ä»¶
                    filtered_df = df[df[rs_col] >= min_rs].sort_values(by=rs_col, ascending=False)
                    
                    # ç”¢ç”Ÿ TradingView æ ¼å¼ (ç¾è‚¡é€šå¸¸ä¸éœ€å‰ç¶´ï¼Œæˆ–è¦– Sheet å…§å®¹åŠ  NASDAQ:/NYSE:)
                    # é€™è£¡ç¤ºç¯„ç›´æ¥è¼¸å‡ºä»£è™Ÿï¼ŒTradingView é€šå¸¸èƒ½è‡ªå‹•è­˜åˆ¥ç¾è‚¡
                    tv_list = filtered_df[symbol_col].astype(str).tolist()
                    csv_string = ",".join(tv_list)
                    
                    st.success(f"æ‰¾åˆ°å…± {len(filtered_df)} æª”ç¬¦åˆæ¢ä»¶çš„ç¾è‚¡")
                    st.subheader("ğŸ”¥ TradingView åŒ¯å…¥å­—ä¸²")
                    st.code(csv_string)
                    
                    st.download_button(
                        label=f"ğŸ“¥ ä¸‹è¼‰ US_{get_tw_time().strftime('%Y_%m_%d')}.txt",
                        data=csv_string,
                        file_name=f"US_{get_tw_time().strftime('%Y_%m_%d')}.txt",
                        mime="text/plain",
                        use_container_width=True
                    )
                    st.dataframe(filtered_df, use_container_width=True)
                else:
                    st.error(f"æ‰¾ä¸åˆ°å°æ‡‰çš„ RS æˆ–ä»£è™Ÿæ¬„ä½ã€‚ç›®å‰çš„æ¬„ä½æœ‰ï¼š{list(df.columns)}")